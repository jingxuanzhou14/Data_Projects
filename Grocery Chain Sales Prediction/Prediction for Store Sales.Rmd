---
title: "HW3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(1)
```

## Import Data
```{r}
library(readxl)
train = read.csv("Train.csv")
test = read.csv("Test.csv")
```

## Method 1: Random Forest Modeling
```{r}
library(randomForest)
library(MASS)
rmse_list.rf = c()
for (i in 1:24) {
     # make Yi be Y (e.g. column Y1 is now named Y)
    traindata = train[1:200,c(2:97,97+i)]
    colnames(traindata) = c(colnames(traindata)[1:96],"Y")
  
    # test data without Y to be used for prediction
    testdata = train[201:250,c(2:97,97+i)]
    colnames(testdata) = c(colnames(testdata)[1:96],"Y")
  
    # modeling 
    rf.sale = randomForest(Y~.,data=traindata,mytry = 8,ntree = 1500)
    yhat.rf= predict(rf.sale,newdata = testdata)
    rmse.rf = sqrt(mean((yhat.rf-testdata$Y)^2))
    print(rmse.rf)
    # store rmse
    rmse_list.rf[i] = rmse.rf
    
}

    # calculate average rmse
    avg_rmse.rf = mean(rmse_list.rf)
    avg_rmse.rf
    # answer is 290
```

## Method 2: Noosted Modeling
```{r}
library(MASS)
library(gbm)
rmse_list.boost = c()
for (i in 1:24) {
     # make Yi be Y (e.g. column Y1 is now named Y)
    traindata = train[1:200,c(2:97,97+i)]
    colnames(traindata) = c(colnames(traindata)[1:96],"Y")
  
    # test data without Y to be used for prediction
    testdata = train[201:250,c(2:97,97+i)]
    colnames(testdata) = c(colnames(testdata)[1:96],"Y")
  
    # modeling 
    boost.sale = gbm(Y~.,traindata,distribution = "gaussian", n.trees=5000,interaction.depth=4,shrinkage=0.0001,verbose=F)
    yhat.boost=predict(boost.sale,newdata=testdata,n.trees=5000)
    rmse.boost = sqrt(mean((yhat.boost-testdata$Y)^2))
    print(rmse.boost)
    # store rmse
    rmse_list.boost[i] = rmse.boost
}
    # calculate average rmse
    avg_rmse.boost = mean(rmse_list.boost)
    avg_rmse.boost
    # answer is 355-374
```

## Method 3: Mars
```{r}
library(MASS)
library(earth)
rmse_list.mars = c()
for (i in 1:24) {
     # make Yi be Y (e.g. column Y1 is now named Y)
    traindata = train[1:200,c(2:97,97+i)]
    colnames(traindata) = c(colnames(traindata)[1:96],"Y")
  
    # test data without Y to be used for prediction
    testdata = train[201:250,c(2:97,97+i)]
    colnames(testdata) = c(colnames(testdata)[1:96],"Y")
  
    # modeling 
    mars.sale = earth(traindata[,-97],traindata[,97], degree=1)
    yhat.mars=predict(mars.sale,newdata=testdata[,-97])
    rmse.mars = sqrt(mean((yhat.mars-testdata$Y)^2))
    print(rmse.mars)
    # store rmse
    rmse_list.mars[i] = rmse.mars
}
    # calculate average rmse
    avg_rmse.mars = mean(rmse_list.mars)
    avg_rmse.mars
    # answer is 317-339
```
## Method 4: Ridge
```{r}
library(ISLR)
library(glmnet)

grid = 10^seq(10,-2,length=100)

rmse_list.ridge = c()
for (i in 1:24) {
     # make Yi be Y (e.g. column Y1 is now named Y)
    traindata = train[1:200,c(2:97,97+i)]
    colnames(traindata) = c(colnames(traindata)[1:96],"Y")
  
    # test data without Y to be used for prediction
    testdata = train[201:250,c(2:97,97+i)]
    colnames(testdata) = c(colnames(testdata)[1:96],"Y")
  
    X = as.matrix(traindata[,-97])
    Y = as.matrix(traindata[,97])
    Z = as.matrix(testdata[,-97])
    
    # cross validation
    cv.out = cv.glmnet(X,Y, alpha=0)
    bestlam = cv.out$lambda.min
  
    # modeling 
    ridge.sale = glmnet(X,Y,alpha=0,lambda=grid,thresh = 1e-12)
    yhat.ridge = predict(ridge.sale,s= bestlam,newx=Z)
    rmse.ridge = sqrt(mean((yhat.ridge-testdata$Y)^2))
    print(rmse.ridge)
    
    # store rmse
    rmse_list.ridge[i] = rmse.ridge
}
    # calculate average rmse
    avg_rmse.ridge = mean(rmse_list.ridge)
    avg_rmse.ridge
    # answer is 277
```
## Method 5: Lasso
```{r}
library(ISLR)
library(glmnet)

grid = 10^seq(10,-2,length=100)

rmse_list.lasso = c()
for (i in 1:24) {
     # make Yi be Y (e.g. column Y1 is now named Y)
    traindata = train[1:200,c(2:97,97+i)]
    colnames(traindata) = c(colnames(traindata)[1:96],"Y")
  
    # test data without Y to be used for prediction
    testdata = train[201:250,c(2:97,97+i)]
    colnames(testdata) = c(colnames(testdata)[1:96],"Y")
  
    X = as.matrix(traindata[,-97])
    Y = as.matrix(traindata[,97])
    Z = as.matrix(testdata[,-97])
    
    # cross validation
    cv.out = cv.glmnet(X,Y, alpha=0)
    bestlam = cv.out$lambda.min
  
    # modeling 
    lasso.sale = glmnet(X,Y,alpha=1,lambda=grid,thresh = 1e-12)
    yhat.lasso = predict(lasso.sale,s= bestlam,newx=Z)
    rmse.lasso = sqrt(mean((yhat.lasso-testdata$Y)^2))
    print(rmse.lasso)
    
    # store rmse
    rmse_list.lasso[i] = rmse.lasso
}
    # calculate average rmse
    avg_rmse.lasso = mean(rmse_list.lasso)
    avg_rmse.lasso
    # answer is 361.4391
```

## Method 6: Neural Networks
```{r}
library(neuralnet)
library(Rcpp)
library(RSNNS)
library(mlbench)

grid = 10^seq(10,-2,length=100)

rmse_list.nn = c()
for (i in 1:24) {
    #scale
    maxs_train = apply(train[,c(2:97)], 2, max) 
    mins_train = apply(train[,c(2:97)], 2, min)
    scaled_train = as.data.frame(scale(train[,c(2:97)],center = mins_train, scale = maxs_train - mins_train))
    
    # NAN
    scaled_train[is.na(scaled_train)] = 0
    
    # make Yi be Y (e.g. column Y1 is now named Y)
    cbind(dt, df[fields])
    hhh = train[1:200,c(97+i)]
    traindata = cbind(scaled_train[1:200,],hhh)
    colnames(traindata) = c(colnames(traindata)[1:96],"Y")
  
    # test data without Y to be used for prediction
    hhhy = train[201:250,c(97+i)]
    testdata = cbind(scaled_train[201:250,],hhhy)
    colnames(testdata) = c(colnames(testdata)[1:96],"Y")
    test_x = testdata[,1:96]
  
    # modeling 
    nn.sale = neuralnet(Y~F1+D1+PR1+P1+F2+D2+PR2+P2+F3+D3+PR3+P3+F4+D4+PR4+P4+F5+D5+PR5+P5+F6+D6+PR6+P6+F7+D7+PR7+P7+F8+D8+PR8+P8+F9+D9+PR9+P9+F10+D10+PR10+P10+F11+D11+PR11+P11+F12+D12+PR12+P12+F13+D13+PR13+P13+F14+D14+PR14+P14+F15+D15+PR15+P15+F16+D16+PR16+P16+F17+D17+PR17+P17+F18+D18+PR18+P18+F19+D19+PR19+P19+F20+D20+PR20+P20+F21+D21+PR21+P21+F22+D22+PR22+P22+F23+D23+PR23+P23+F24+D24+PR24+P24, data = traindata, linear.output = T, hidden = 3)
    yhat.nn = compute(nn.sale, test_x)
    rmse.nn = sqrt(mean((yhat.nn$net.result-testdata$Y)^2) )
    print(rmse.nn)
    
    # store rmse
    rmse_list.nn[i] = rmse.nn
}
    # calculate average rmse
    avg_rmse.nn = mean(rmse_list.nn)
    avg_rmse.nn
    # answer is 
```

## Method 7: Linear Regression
```{r}
rmse_list.lm = c()
for (i in 1:24) {
     # make Yi be Y (e.g. column Y1 is now named Y)
    traindata = train[1:200,c(2:97,97+i)]
    colnames(traindata) = c(colnames(traindata)[1:96],"Y")
  
    # test data without Y to be used for prediction
    testdata = train[201:250,c(2:97,97+i)]
    colnames(testdata) = c(colnames(testdata)[1:96],"Y")
  
    # modeling 
    lm.sale = lm(Y~.,data=traindata)
    yhat.rf= predict(lm.sale,newdata = testdata)
    rmse.rf = sqrt(mean((yhat.rf-testdata$Y)^2))
    print(rmse.rf)
    # store rmse
    rmse_list.rf[i] = rmse.rf
    
}

    # calculate average rmse
    avg_rmse.rf = mean(rmse_list.rf)
    avg_rmse.rf
    # answer is 290
```